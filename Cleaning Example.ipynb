{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Demonstrate cleaning functions in action\n",
    "\n",
    "# 1. Load data\n",
    "# 2. Converting to date-time \n",
    "# 3. Negative value check\n",
    "# 4. Visualise gaps in data\n",
    "# 4.1. Hourly cycles\n",
    "# 4.2. Weekly?\n",
    "# 4.3. Daily cycles\n",
    "# 5. Fill Missing Values\n",
    "# 5. Interpolator\n",
    "# 6. Upload/Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "# from sklearn.preprocessing import Imputer --> doesn't work\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data\n",
    "\n",
    "def initialise_data(file_name, cols=[]):\n",
    "\n",
    "    \"\"\"\n",
    "    This function loads the file into a dataframe and imports the packages needed, ready for cleaning.\n",
    "\n",
    "    Parameters:\n",
    "    file_name : specify the directory path and file name of the dataset\n",
    "    file_format :  provide the format of the original tabular dataset (eg., csv, excel) \n",
    "    columns : provide the name of the columns as a list for the dataframe, ensure list length = number of columns\n",
    "    \"\"\"\n",
    "    \n",
    "    x = {\"xlsx\": pd.read_excel, \"csv\": pd.read_csv} \n",
    "    df = x[file_name.split(\".\")[1]](file_name, header=None, index_col=False)\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "cols = [\n",
    "    'Unique Meter ID', \n",
    "    'Unix Time Stamp', \n",
    "    'Date/Time Stamp', \n",
    "    'Incremental Consumption Value (Gallons)', \n",
    "    'Reading Value (Gallons)',\n",
    "    'Some data'\n",
    "]\n",
    "\n",
    "df = initialise_data('Sample_UtilityX_AMIData.csv',cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Converting to date-time \n",
    "\n",
    "def convert_to_datetime(df, time_col):\n",
    "    \"\"\"\n",
    "    Functions convert time column to datetime format\n",
    "    df: input your dataframe\n",
    "    time_col: the time column in your dataframe\n",
    "    \"\"\"\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    return df\n",
    "\n",
    "df = convert_to_datetime(df, 'Date/Time Stamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1. Negative value check\n",
    "\n",
    "# Increase efficiency \n",
    "\n",
    "def negative_value_check(df, opt, id_col, cons_col):\n",
    "    \"\"\"\n",
    "    id_col is header of column with Meter ID\n",
    "    cons_col is header of column with Consumption Values\n",
    "    dataframe is your full dataframe\n",
    "    opt is either 'remove' (removes meters with negative values), \n",
    "    'show' (shows ALL meter entries with negative values),\n",
    "    'list' (lists UNIQUE meter IDs with negative values in an array) or 'both' \n",
    "    (returns a new dataframe with both negative and positive values and marks them)\n",
    "    \"\"\"\n",
    "\n",
    "    df['Negative?'] = 0\n",
    "    df.loc[df[cons_col] < 0, 'Negative?'] = 1\n",
    "\n",
    "    if opt == 'remove':\n",
    "        df = df.loc[df['Negative?'] == 0]\n",
    "        df.drop('Negative?', axis=1, inplace=True)\n",
    "        return df\n",
    "    elif opt == 'show':\n",
    "        df = df.loc[df['Negative?'] == 1]\n",
    "        df.drop('Negative?', axis=1, inplace=True)\n",
    "        return df\n",
    "    elif opt == 'list':\n",
    "        df = df.loc[df[cons_col] < 0, id_col].unique()\n",
    "        df.drop('Negative?', axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "negative_value_check(df, 'show','Unique Meter ID','Incremental Consumption Value (Gallons)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2. NaN value check\n",
    "\n",
    "def NaN_value_check(df, opt, id_col, cons_col):\n",
    "    \"\"\"\n",
    "    dataframe is your full dataframe\n",
    "    id_col is header of column with Meter ID\n",
    "    cons_col is header of column with Consumption Values\n",
    "    opt is either 'remove' (removes meters with negative values), \n",
    "    'show' (shows ALL meter entries with negative values),\n",
    "    'list' (lists UNIQUE meter IDs with negative values in an array) or 'both' \n",
    "    (returns a new dataframe with both negative and positive values and marks them)\n",
    "    \"\"\"\n",
    "    \n",
    "    if opt == 'remove':\n",
    "        return df.loc[df[id_col].isna()]\n",
    "    elif opt == 'show':\n",
    "        return df.loc[df[id_col].isna() == True]\n",
    "    elif opt == 'list':\n",
    "        pass # complete \n",
    "    return df\n",
    "\n",
    "NaN_value_check(df, 'show', 'Unique Meter ID','Incremental Consumption Value (Gallons)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Incremental Consumption Value (Gallons)'].isna() \n",
    "\n",
    "# df[df['Incremental Consumption Value (Gallons)'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop[df['Incremental Consumption Value (Gallons)'] == np.NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df['Incremental Consumption Value (Gallons)'] == np.NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Reading Value (Gallons)'].isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Some data'].isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Negative?'] = 0\n",
    "df.loc[df['Incremental Consumption Value (Gallons)'] < 0, 'Negative?'] = 1\n",
    "df.loc[df['Negative?'] == 1]\n",
    "\n",
    "# Weird results\n",
    "# Increment value says -10, yet Reading value increases by 10\n",
    "# Also timestamps are not chronological\n",
    "# Some timestamps are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualise gaps in data\n",
    "# make time-related columns for analysis over various periods\n",
    "df['dotw'] = df['Date/Time Stamp'].dt.dayofweek\n",
    "df['hour'] = df['Date/Time Stamp'].dt.hour\n",
    "df['doty'] = df['Date/Time Stamp'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. Diurnal cycles\n",
    "\n",
    "sns.lineplot(\n",
    "    x='hour',\n",
    "    y='Incremental Consumption Value (Gallons)',\n",
    "    data=df\n",
    ")\n",
    "# Line indicates mean each hour\n",
    "# Shadow indicates 95% confidence interval\n",
    "# Plot correponds to expected behaviour, high in morning, late afternoon and evening/night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Weekly cycles \n",
    "\n",
    "sns.lineplot(\n",
    "    x='dotw',\n",
    "    y='Incremental Consumption Value (Gallons)',\n",
    "    data=df\n",
    ")\n",
    "\n",
    "# Strange behaviour, should be consistent through weekdays \n",
    "# Delve deeper into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3. Yearly cycles\n",
    "\n",
    "sns.lineplot(\n",
    "    x='doty',\n",
    "    y='Incremental Consumption Value (Gallons)',\n",
    "    data=df\n",
    ")\n",
    "\n",
    "# This definitely deviates from expectations!\n",
    "# Huge dips in spring/summer\n",
    "# Random dips occassionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(\n",
    "    df['Unique Meter ID'].value_counts(), \n",
    "    on='Unique Meter ID',\n",
    "    rsuffix='000',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Unique Meter ID', 'Unix Time Stamp', 'Date/Time Stamp',\n",
    "       'Incremental Consumption Value (Gallons)', 'Reading Value (Gallons)',\n",
    "       'Negative?','dotw', 'hour', 'doty' ,'data_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,10))\n",
    "sns.lineplot(\n",
    "    x='doty',\n",
    "    y='Incremental Consumption Value (Gallons)',\n",
    "    data=df.loc[df['data_count'] > 8700],\n",
    "    ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[df['data_count'] > 8700]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cons = raw_df.groupby(['Unique Meter ID', 'doty']).\\\n",
    "    agg({'Incremental Consumption Value (Gallons)':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill data set missing value with mean\n",
    "def fill_with_mean(data, features, show_info=False):\n",
    "    \"\"\"\n",
    "    :type data: pandas DataFrame\n",
    "    \"\"\"\n",
    "    df = data.loc[:, features]\n",
    "    print('begin filling...')\n",
    "    for ele in features:\n",
    "        if show_info == True:\n",
    "            print(ele)\n",
    "        p = df.loc[:, ele]\n",
    "        p[p.isna()] = p[p.notna()].mean()\n",
    "        df[ele] = p\n",
    "    print('finished! merge result...')\n",
    "    for ele in features:\n",
    "        if show_info == True:\n",
    "            print(ele)\n",
    "        data[ele] = df.loc[:, ele]\n",
    "    print('successflly done!')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill data set missing value with mean (integer mean)\n",
    "def fill_with_int_mean(data, features, show_info=False):\n",
    "    \"\"\"\n",
    "    :type data: pandas DataFrame\n",
    "    \"\"\"\n",
    "    df = data.loc[:, features]\n",
    "    print('begin filling...')\n",
    "    for ele in features:\n",
    "        if show_info == True:\n",
    "            print(ele)\n",
    "        p = df.loc[:, ele]\n",
    "        p[p.isna()] = int(p[p.notna()].mean())\n",
    "        df[ele] = p\n",
    "    print('finished! merge result...')\n",
    "    for ele in features:\n",
    "        if show_info == True:\n",
    "            print(ele)\n",
    "        data[ele] = df.loc[:, ele]\n",
    "    print('successflly done!')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill datas et missing value with most frequent value\n",
    "def fill_with_mode(data, features, show_info=False):\n",
    "    \"\"\"\n",
    "    :type data: pandas DataFrame\n",
    "    \"\"\"\n",
    "    df = data.loc[:, features]\n",
    "    print('begin filling...')\n",
    "    for ele in features:\n",
    "        if show_info == True:\n",
    "            print(ele)\n",
    "        p = df.loc[:, ele]\n",
    "        p[p.isna()] = p[p.notna()].mode()[0]\n",
    "        df[ele] = p\n",
    "    print('finished! merge result...')\n",
    "    for ele in features:\n",
    "        if show_info == True:\n",
    "            print(ele)\n",
    "        data[ele] = df.loc[:, ele]\n",
    "    print('successflly done!')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill data set missing value with median\n",
    "def fill_with_median(data):\n",
    "    imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "    if len(data.shape) == 1:\n",
    "        data_new = imp.fit_transform(data.values.reshape(-1, 1))\n",
    "    else:\n",
    "        data_new = imp.fit_transform(data.values)\n",
    "    data.values = data_new\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Fill Missing values\n",
    "# Using kNN to predict missing value\n",
    "def fill_with_KNN_(data, best_k, train_feature_list, target_feature, model='class'):\n",
    "    predictor = data[train_feature_list]\n",
    "    target = data[target_feature]\n",
    "    index_na = target[target.isna()].index.values\n",
    "    index_notna = target[target.notna()].index.values\n",
    "\n",
    "    X_train = predictor.loc[index_notna, :].values\n",
    "    y_train = target.loc[index_notna].values\n",
    "    X_test = predictor.loc[index_na, :].values\n",
    "\n",
    "    print('begin train ......')\n",
    "    if model == 'class':\n",
    "        knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "    if model == 'reg':\n",
    "        knn = KNeighborsRegressor(n_neighbors=best_k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "    print('successful preidct')\n",
    "\n",
    "    p1 = target.loc[index_na]\n",
    "    p2 = pd.Series(y_pred, index=p1.index.values)\n",
    "    p3 = target[target.notna()]\n",
    "    p2 = p2.append(p3)\n",
    "    p2 = p2.sort_index(axis=0)\n",
    "    data[target_feature] = p2\n",
    "    print('successfully deal with missing value with data.')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Interpolate missing values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
